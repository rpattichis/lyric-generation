{"cells":[{"cell_type":"markdown","source":["# GPT-3 Baselines\n","\n","This notebook trains the necessary models for our baseline comparisons."],"metadata":{"id":"vpGGPbUpgi64"}},{"cell_type":"markdown","source":["### Set-up"],"metadata":{"id":"tpMbzRm7gw21"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lxWzjDUj7hf"},"outputs":[],"source":["from IPython.display import clear_output "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25679,"status":"ok","timestamp":1670778851317,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"ARqW1wC_U94G","outputId":"8816e46b-a8a3-4ec3-b93d-40d210f5531b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive/')\n","os.chdir('/content/drive/Shareddrives/CS260-Project/data/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sOuVkOO3kcu"},"outputs":[],"source":["!pip install --upgrade openai\n","clear_output()"]},{"cell_type":"markdown","source":["## GPT-3 Fine-tuning\n","\n","Referenced https://beta.openai.com/docs/guides/fine-tuning and https://beta.openai.com/docs/api-reference/fine-tunes"],"metadata":{"id":"Ko-0a2xMhKti"}},{"cell_type":"markdown","source":["### Prepare data\n"],"metadata":{"id":"k6tEfeNRg13q"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3024,"status":"ok","timestamp":1670738729794,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"rfM9eiBM_CFd","outputId":"dc519089-5aa8-439f-8c2f-365faf662bfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Analyzing...\n","\n","- Based on your file extension, your file is formatted as a CSV file\n","- Your file contains 1000 prompt-completion pairs\n","- There are 1 duplicated prompt-completion sets. These are rows: [934]\n","- There are 2 examples that are very long. These are rows: [419, 465]\n","For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n","- All prompts end with suffix `\\n\\n###\\n\\n`\n","- All completions end with suffix `###`\n","\n","Based on the analysis we will perform the following actions:\n","- [Necessary] Your format `CSV` will be converted to `JSONL`\n","- [Recommended] Remove 1 duplicate rows [Y/n]: Y\n","- [Recommended] Remove 2 long examples [Y/n]: Y\n","\n","\n","Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n","\n","Wrote modified file to `../data/train/40-topic-sample-1000-train_prepared.jsonl`\n","Feel free to take a look!\n","\n","Now use that file when fine-tuning:\n","> openai api fine_tunes.create -t \"../data/train/40-topic-sample-1000-train_prepared.jsonl\"\n","\n","After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"###\"]` so that the generated texts ends at the expected place.\n","Once your model starts training, it'll approximately take 51.25 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n","Analyzing...\n","\n","- Based on your file extension, your file is formatted as a CSV file\n","- Your file contains 100 prompt-completion pairs\n","- All prompts end with suffix `\\n\\n###\\n\\n`\n","- All completions end with suffix `###`\n","\n","Based on the analysis we will perform the following actions:\n","- [Necessary] Your format `CSV` will be converted to `JSONL`\n","\n","\n","Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n","\n","Wrote modified file to `../data/val/40-topic-sample-1000-val_prepared.jsonl`\n","Feel free to take a look!\n","\n","Now use that file when fine-tuning:\n","> openai api fine_tunes.create -t \"../data/val/40-topic-sample-1000-val_prepared.jsonl\"\n","\n","After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"###\"]` so that the generated texts ends at the expected place.\n","Once your model starts training, it'll approximately take 3.82 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"]}],"source":["# convert csv to JSONL\n","!openai tools fine_tunes.prepare_data -f ../data/train/40-topic-sample-1000-train.csv -q\n","!openai tools fine_tunes.prepare_data -f ../data/val/40-topic-sample-1000-val.csv -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TerI6AzjUQqR"},"outputs":[],"source":["import openai"]},{"cell_type":"markdown","metadata":{"id":"TpWxAxY-9HO6"},"source":["### Train using OpenAI API\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BW0h4-GDxysi","executionInfo":{"status":"ok","timestamp":1670788691796,"user_tz":480,"elapsed":466814,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"}},"outputId":"b968a683-c6ad-4f85-c03e-518f85ff13de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found potentially duplicated files with name '20-topic-sample-1000-train_prepared.jsonl', purpose 'fine-tune' and size 1261752 bytes\n","file-ffXSdsRSY794IoGdX08aLSBa\n","Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: file-ffXSdsRSY794IoGdX08aLSBa\n","Reusing already uploaded file: file-ffXSdsRSY794IoGdX08aLSBa\n","Found potentially duplicated files with name '20-topic-sample-1000-val_prepared.jsonl', purpose 'fine-tune' and size 137961 bytes\n","file-w2QiH5QgZrWfzlEbwkge5CgA\n","Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: file-w2QiH5QgZrWfzlEbwkge5CgA\n","Reusing already uploaded file: file-w2QiH5QgZrWfzlEbwkge5CgA\n","Created fine-tune: ft-3zyYbSvoKrgcLJkY0gBu8Skm\n","Streaming events until fine-tuning is complete...\n","\n","(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n","[2022-12-11 19:50:43] Created fine-tune: ft-3zyYbSvoKrgcLJkY0gBu8Skm\n","[2022-12-11 19:50:47] Fine-tune costs $7.39\n","[2022-12-11 19:50:47] Fine-tune enqueued. Queue number: 0\n","[2022-12-11 19:50:51] Fine-tune started\n","[2022-12-11 19:54:27] Completed epoch 1/8\n","[2022-12-11 19:57:15] Completed epoch 2/8\n","\n","Stream interrupted. Job is still running.\n","To resume the stream, run:\n","\n","  openai api fine_tunes.follow -i ft-3zyYbSvoKrgcLJkY0gBu8Skm\n","\n","To cancel your job, run:\n","\n","  openai api fine_tunes.cancel -i ft-3zyYbSvoKrgcLJkY0gBu8Skm\n","\n"]}],"source":["# Create fine-tuning job\n","!export OPENAI_API_KEY=\"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\"; openai api fine_tunes.create -t train/20-topic-sample-1000-train_prepared.jsonl -v val/20-topic-sample-1000-val_prepared.jsonl --model curie --n_epochs 8 --batch_size 5\n","# !export OPENAI_API_KEY=\"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\"; openai api fine_tunes.create -t train/30-topic-sample-1000-train_prepared.jsonl -v val/30-topic-sample-1000-val_prepared.jsonl --model curie --n_epochs 5 --batch_size 5\n","# !export OPENAI_API_KEY=\"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\"; openai api fine_tunes.create -t train/40-topic-sample-1000-train_prepared.jsonl -v val/40-topic-sample-1000-val_prepared.jsonl --model curie --n_epochs 2 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1989,"status":"ok","timestamp":1670789694525,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"odKR5wfp3kUs","outputId":"ace7bd41-c0b1-496d-8fe6-438157cdddac"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-12-11 19:50:43] Created fine-tune: ft-3zyYbSvoKrgcLJkY0gBu8Skm\n","[2022-12-11 19:50:47] Fine-tune costs $7.39\n","[2022-12-11 19:50:47] Fine-tune enqueued. Queue number: 0\n","[2022-12-11 19:50:51] Fine-tune started\n","[2022-12-11 19:54:27] Completed epoch 1/8\n","[2022-12-11 19:57:15] Completed epoch 2/8\n","[2022-12-11 20:00:02] Completed epoch 3/8\n","[2022-12-11 20:02:49] Completed epoch 4/8\n","[2022-12-11 20:05:34] Completed epoch 5/8\n","[2022-12-11 20:08:20] Completed epoch 6/8\n","[2022-12-11 20:11:08] Completed epoch 7/8\n","[2022-12-11 20:13:56] Completed epoch 8/8\n","[2022-12-11 20:14:21] Uploaded model: curie:ft-personal-2022-12-11-20-14-21\n","[2022-12-11 20:14:22] Uploaded result file: file-1XHOnkjGVedUJl2Ca1fRVALi\n","[2022-12-11 20:14:22] Fine-tune succeeded\n","\n","Job complete! Status: succeeded ðŸŽ‰\n","Try out your fine-tuned model:\n","\n","openai api completions.create -m curie:ft-personal-2022-12-11-20-14-21 -p <YOUR_PROMPT>\n"]}],"source":["# Reconnect to fine-tune if needed (change job number)\n","!export OPENAI_API_KEY=\"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\"; openai api fine_tunes.follow -i ft-3zyYbSvoKrgcLJkY0gBu8Skm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3r7-Gozo4fsp"},"outputs":[],"source":["# Output learning logs to csv file -- includes training + val loss\n","!export OPENAI_API_KEY=\"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\"; openai api fine_tunes.results -i \"ft-3zyYbSvoKrgcLJkY0gBu8Skm\" > ../models/20-topic-long_results.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1X1f2gqabwM-"},"outputs":[],"source":["# Lists all fine-tuning jobs\n","!export OPENAI_API_KEY=\"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\"; openai api fine_tunes.list"]},{"cell_type":"markdown","metadata":{"id":"O_uWREQAqXzK"},"source":["## Saved Models (Under Jon's Key):\n","100 samples Ada (\\$0.03) - ada:ft-personal-2022-11-28-23-54-15\n","\n","100 samples Davinci (\\$2.38) - davinci:ft-personal-2022-11-28-23-59-14\n","\n","1000 samples Curie (\\$5.69) - curie:ft-personal-2022-11-29-01-05-27\n"]},{"cell_type":"markdown","metadata":{"id":"8OXJwLDv_sNC"},"source":["## Saved Models -- used validation (Under Avalon's Key)\n","\n","100 samples Ada (5 epochs) (\\$0.08) - ada:ft-personal-2022-12-01-18-55-30\n","\n","100 samples Davinci (2 epochs) (\\$2.38) - davinci:ft-personal-2022-12-01-21-52-58\n","\n","1000 samples Curie (5 epochs) (\\$5.69) - curie:ft-personal-2022-12-01-22-22-07"]},{"cell_type":"markdown","metadata":{"id":"eGuJxlD4w4ub"},"source":["## Saved Models -- used validation, 1000 samples, Curie, 2 epochs (Under Rebecca's Key)\n","\n","10 topics (\\$1.85) - curie:ft-personal-2022-12-11-07-06-32 (job # ft-lJjy7Vy4YgvdKUFNxEBwKagl)\n","\n","20 topics (\\$1.85) - curie:ft-personal-2022-12-11-07-29-55 (job # ft-YuOkTUjYioWnlHfL0y3lObkQ)\n","\n","30 topics (\\$1.85) - curie:ft-personal-2022-12-11-07-45-58 (job # ft-1X7lY2DgzRGmiEpkCWaP47Rk)\n","\n","40 topics (\\$1.85) - curie:ft-personal-2022-12-11-08-01-49 (job # ft-Rf32YslUXVD2AfZvRltsySYu)\n"]},{"cell_type":"markdown","source":["## Saved Models -- used validation, 1000 samples, Curie, batch size 5 (Under Christina's Key)\n","\n","10 topics (2 epochs) (\\$1.85) - curie:ft-personal-2022-12-11-18-54-16 (job # ft-11yKZpdsDKkFYb8CNMKIixNx)\n","\n","20 topics (2 epochs) (\\$1.85) - curie:ft-personal-2022-12-11-19-08-29 (job # ft-YuOkTUjYioWnlHfL0y3lObkQ)\n","\n","30 topics (5 epochs) (\\$4.62) - curie:ft-personal-2022-12-11-19-34-45 (job # ft-Ps74y6roPjIEIlxr74L0CRIV)\n","\n","20 topics (8 epochs) (\\$7.39) - curie:ft-personal-2022-12-11-20-14-21 (job # ft-3zyYbSvoKrgcLJkY0gBu8Skm)"],"metadata":{"id":"HiJ2rEyhjtWF"}},{"cell_type":"markdown","source":["### Use fine-tuned models"],"metadata":{"id":"doMTy43si4ql"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUWOFYc0lYJJ"},"outputs":[],"source":["import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtyuu5uV3My0"},"outputs":[],"source":["# get single instances of prompt/lyrics\n","data = []\n","with open('../data/train/lda-train-6-formatted.csv', 'r') as orig_data:\n","  reader = csv.reader(orig_data, delimiter = ',')\n","  for row in reader:\n","    data.append(row)\n","\n","exist_prompt, exist_lyric = data[15]   # prompt that exists in both data sets (only appears once)\n","last_prompt, last_lyric = data[-1]    # unseen prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670021965889,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"4oN9Q2i-EHUp","outputId":"1ad4992a-e6b3-4c4f-e81d-c2ff3b80f320"},"outputs":[{"name":"stdout","output_type":"stream","text":["Keith Urban;2\n","\n","###\n","\n","\n"]}],"source":["print(exist_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVZWKgkv9Ubo"},"outputs":[],"source":["# All models that were used and their necessary keys\n","models_avalon = {\n","    \"key\": \"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\",\n","    \"ada\": \"ada:ft-personal-2022-12-01-18-55-30\",\n","    \"curie\": \"curie:ft-personal-2022-12-01-22-22-07\",\n","    \"davinci\": \"davinci:ft-personal-2022-12-01-21-52-58\"\n","}\n","models_jon = {\n","    \"key\": \"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\",\n","    \"ada\": \"ada:ft-personal-2022-11-28-23-54-15\",\n","    \"curie\": \"curie:ft-personal-2022-11-29-01-05-27\",\n","    \"davinci\": \"davinci:ft-personal-2022-11-28-23-59-14\"\n","}\n","models_rebecca = {\n","    \"key\": \"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\"\n","}\n","models_christina = {\n","    \"key\": \"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\",\n","    \"curie-10\": \"curie:ft-personal-2022-12-11-18-54-16\",\n","    \"curie-30\": \"curie:ft-personal-2022-12-11-19-34-45\",\n","    \"curie-20-short\": \"curie:ft-personal-2022-12-11-19-08-29\",\n","    \"curie-20-long\": \"curie:ft-personal-2022-12-11-20-14-21\"\n","}\n","\n","models = models_christina\n","openai.api_key = models[\"key\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUTuI7LL51tl"},"outputs":[],"source":["# test with existing prompts (evaluates on all prompts from validation set)\n","\n","# 1000 samples (curie)\n","with open('../data/val/sample-1000-val.csv', 'r') as val:\n","  reader = csv.reader(val, delimiter = ',')\n","  with open('../data/out/out-1000-samples-val.txt', 'w') as out:\n","    i = 0\n","    for row in reader:\n","      if i > 0:\n","        prompt = row[0]\n","        result = openai.Completion.create(\n","            model=models[\"curie\"],\n","            prompt=prompt,\n","            max_tokens=1000,\n","            stop=\"###\")\n","        out.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","      i += 1\n","print(\"Generated lyric: \" + result.choices[0][\"text\"] + \"\\n\\n\")\n","print(\"Original lyric: \" + exist_lyric)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrEz_j5IMxrZ"},"outputs":[],"source":["# 100 samples (davinci)\n","with open('../data/val/sample-100-val.csv', 'r') as val:\n","  reader = csv.reader(val, delimiter = ',')\n","  with open('../data/out/out-100-samples-val.txt', 'w') as out:\n","    i = 0\n","    for row in reader:\n","      if i > 0:\n","        prompt = row[0]\n","        result = openai.Completion.create(\n","            model=models[\"davinci\"],\n","            prompt=prompt,\n","            max_tokens=1000,\n","            stop=\"###\")\n","        out.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","      i += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLaQk8OTB7Sz"},"outputs":[],"source":["print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yF4fRSS08-hQ"},"outputs":[],"source":["# test unseen prompts (samples from test set)\n","\n","# 100 samples (davinci)\n","with open('../data/test/lda-test-6-formatted.csv', 'r') as val:\n","  reader = csv.reader(val, delimiter = ',')\n","  with open('../data/out/out-100-samples-test.txt', 'w') as out:\n","    i = 0\n","    for row in reader:\n","      if i > 0 and i < 11:\n","        prompt = row[0]\n","        result = openai.Completion.create(\n","            model=models[\"davinci\"],\n","            prompt=prompt,\n","            max_tokens=1000,\n","            stop=\"###\")\n","        out.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","      i += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eau8RtJ-OFha"},"outputs":[],"source":["# 1000 samples (curie -- change input file as needed)\n","with open('../data/test/big-lda-test-30-formatted.csv', 'r') as val:\n","  reader = csv.reader(val, delimiter = ',')\n","  with open('../data/out/gpt3/fine-tunning/out-30-topics.txt', 'w') as out:\n","    i = 0\n","    for row in reader:\n","      if i > 0 and i < 101:\n","        prompt = row[0]\n","        result = openai.Completion.create(\n","            model=models[\"curie-30\"],\n","            prompt=prompt,\n","            max_tokens=1000,\n","            stop=\"###\")\n","        out.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","      i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12390,"status":"ok","timestamp":1670528248813,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"9r2V1_kDN-lL","outputId":"06f4c617-355a-4da7-acba-15b3a4f631f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Taylor Swift;5<START>\n","\n","I'm coming for you\n","You think you're so righteous\n","I'm coming for you\n","You'd like that wouldn't you\n","We feel so much the same\n","I thought I knew you\n","You thought I was blind\n","We feel so much the same\n","\n","I'm coming for you\n","Hold on to your pants\n","I just have to know you\n","We feel so much the same\n","I thought I knew you\n","You thought I was blind\n","We feel so much the same\n","\n","We had such a spectacular summer\n","That hurt way too much to ever forget it\n","We had such similarly structured arguments\n","That hurt way too much to ever forgive\n","Here we are now\n","It's the last summer\n","So hold on to your pants\n","Cause this just got serious\n","Here we are now\n","It's the last summer\n","So don't you ever forget it\n","\n","You're only human girl\n","I won't forget you\n","I only like to hurt humans\n","I'll beat your<END>\n","\n","\n"]}],"source":["# single prompt for testing\n","result = openai.Completion.create(\n","    model=models[\"curie\"],\n","    prompt=\"Taylor Swift;3\",\n","    max_tokens=1000,\n","    stop=\"###\")\n","print(\"Taylor Swift;5\" + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"RtV9MvcUiLee"},"source":["## Few-shot Baselines"]},{"cell_type":"markdown","metadata":{"id":"tJkjVWT0mmIO"},"source":["### Using 6 topic set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jH3952nliOVg"},"outputs":[],"source":["# Samples w same topics\n","raw_data = []\n","with open('../data/train/lda-train-6.csv', 'r') as orig_data:\n","  reader = csv.reader(orig_data, delimiter = ',')\n","  i = 0\n","  for row in reader:\n","    if i > 0 and i < 1000:\n","      raw_data.append(row)\n","    i += 1\n","\n","num_samples = 1   # Number of samples for each topic\n","by_topic = [[] for i in range(6)]\n","for artist, topic_id, lyric in raw_data:\n","  id = int(topic_id)\n","  if len(by_topic[id]) < num_samples * 15:\n","    by_topic[id].append((artist, lyric))\n","\n","input_artist = \"Taylor Swift\"\n","input_topic = 0\n","\n","prompts_topic = [\"\" for i in range(6)]  # Examples separated by topic\n","prompt_gen = \"\"  # Example with all topics\n","for id, topic in enumerate(by_topic):\n","  i = 0\n","  for artist, lyric in topic:\n","    prompts_topic[id] += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","    if i < num_samples:\n","      prompt_gen += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","      i += 1\n","  prompts_topic[id] += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\n Lyrics: \"\n","prompt_gen += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\nLyrics: \""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXKEvnuV2v_S"},"outputs":[],"source":["for artist, _ in by_topic[id]:\n","  print(artist + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11134,"status":"ok","timestamp":1670370876915,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"75QSAW-GuNgS","outputId":"9f061154-f73e-4659-95f0-f99be70b30f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","It's a game, a cruel game\n","Played on cards too dark to see\n","I was drawn in by your beauty\n","Your touch has brought me to my knees\n","\n","And I'm not sure what this means\n","Oh, what this could ever be\n","But I feel like I'm falling for you\n","Falling without knowing why\n","\n","Falling so fast\n","I'm tumbling over time\n","So deep, so close\n","I feel the magnitude\n","For taking a chance on you\n","\n","It's a long shot, a long run\n","A journey with no return\n","But I'm willing to take the risk\n","For a chance to feel your touch\n","\n","Cause I'm not sure what this means\n","Oh, what this could ever be\n","But I feel like I'm falling for you\n","Falling without knowing why\n","\n","Falling so fast\n","I'm tumbling over time\n","So deep, so close\n","I feel the magnitude\n","For taking a chance on you\n","\n","Every single moment with you\n","Is a moment on borrowed time\n","But I'm not sure if I'm ready\n","To open up my heart this time\n","\n","And I'm not sure what this means\n","Oh, what this could ever be\n","But I feel like I'm falling for you\n","Falling without knowing why\n","\n","Falling so fast\n","I'm tumbling over time\n","So deep, so close\n","I feel the magnitude\n","For taking a chance on you\n"]}],"source":["# Example includes all topics\n","result = openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt=prompt_gen,\n","    max_tokens=400,\n","    stop=\"###\")\n","print(result.choices[0][\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1670370887895,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"Ixx77LMFz90j","outputId":"1b05ce3e-604b-4f27-96ec-32ad62cfead8"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"text\": \"\\nIt's a game, a cruel game\\nPlayed on cards too dark to see\\nI was drawn in by your beauty\\nYour touch has brought me to my knees\\n\\nAnd I'm not sure what this means\\nOh, what this could ever be\\nBut I feel like I'm falling for you\\nFalling without knowing why\\n\\nFalling so fast\\nI'm tumbling over time\\nSo deep, so close\\nI feel the magnitude\\nFor taking a chance on you\\n\\nIt's a long shot, a long run\\nA journey with no return\\nBut I'm willing to take the risk\\nFor a chance to feel your touch\\n\\nCause I'm not sure what this means\\nOh, what this could ever be\\nBut I feel like I'm falling for you\\nFalling without knowing why\\n\\nFalling so fast\\nI'm tumbling over time\\nSo deep, so close\\nI feel the magnitude\\nFor taking a chance on you\\n\\nEvery single moment with you\\nIs a moment on borrowed time\\nBut I'm not sure if I'm ready\\nTo open up my heart this time\\n\\nAnd I'm not sure what this means\\nOh, what this could ever be\\nBut I feel like I'm falling for you\\nFalling without knowing why\\n\\nFalling so fast\\nI'm tumbling over time\\nSo deep, so close\\nI feel the magnitude\\nFor taking a chance on you\"\n","    }\n","  ],\n","  \"created\": 1670370868,\n","  \"id\": \"cmpl-6Kc3YUcoIFxOHbC7tIxeMUEnO9yIM\",\n","  \"model\": \"text-davinci-003\",\n","  \"object\": \"text_completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 296,\n","    \"prompt_tokens\": 2068,\n","    \"total_tokens\": 2364\n","  }\n","}\n"]}],"source":["print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9062,"status":"ok","timestamp":1670370426455,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"gEFJU7XguWxk","outputId":"c527bb01-c604-4deb-d7e4-8476ded44e05"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Verse 1\n","I've seen love, I've seen lies\n","Searching for truth in between black and white\n","Your dream world, no disguise\n","Just one chance, don't let it ride\n","\n","Pre-Chorus\n","Lightning strikes and then it fades away\n","Missing moment, running out of time to play\n","\n","Chorus\n","My hero, my enemy\n","My constant changing, adrenaline\n","My precious curse for eternity\n","My hero, my enemy\n","\n","Verse 2\n","I've seen pain, I've seen pride\n","Sometimes we fight, but still make it through the night\n","The stormy clouds, they pass by\n","You can stay, and just be mine\n","\n","Pre-Chorus\n","Lightning strikes and then it fades away\n","I'm calling out, whatever it takes to stay\n","\n","Chorus\n","My hero, my enemy\n","My constant changing, adrenaline\n","My precious curse for eternity\n","My hero, my enemy\n","\n","Bridge\n","Your love, it's like a symphony\n","Play it loud, so I'll never feel alone\n","My miracle, it brings me back again\n","I'll be your hero, you be my enemy\n","\n","Chorus\n","My hero, my enemy\n","My constant changing, adrenaline\n","My precious curse for eternity\n","My hero, my enemy\n"]}],"source":["# Examples includes requested topic\n","result = openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt=prompts_topic[input_topic],\n","    max_tokens=400,\n","    stop=\"###\")\n","print(result.choices[0][\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1670370426457,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"8AdhY6-K0kVY","outputId":"fcfcda6a-8f4b-482e-dacd-1e9e28152b78"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"text\": \"\\nVerse 1\\nI've seen love, I've seen lies\\nSearching for truth in between black and white\\nYour dream world, no disguise\\nJust one chance, don't let it ride\\n\\nPre-Chorus\\nLightning strikes and then it fades away\\nMissing moment, running out of time to play\\n\\nChorus\\nMy hero, my enemy\\nMy constant changing, adrenaline\\nMy precious curse for eternity\\nMy hero, my enemy\\n\\nVerse 2\\nI've seen pain, I've seen pride\\nSometimes we fight, but still make it through the night\\nThe stormy clouds, they pass by\\nYou can stay, and just be mine\\n\\nPre-Chorus\\nLightning strikes and then it fades away\\nI'm calling out, whatever it takes to stay\\n\\nChorus\\nMy hero, my enemy\\nMy constant changing, adrenaline\\nMy precious curse for eternity\\nMy hero, my enemy\\n\\nBridge\\nYour love, it's like a symphony\\nPlay it loud, so I'll never feel alone\\nMy miracle, it brings me back again\\nI'll be your hero, you be my enemy\\n\\nChorus\\nMy hero, my enemy\\nMy constant changing, adrenaline\\nMy precious curse for eternity\\nMy hero, my enemy\"\n","    }\n","  ],\n","  \"created\": 1670370419,\n","  \"id\": \"cmpl-6KbwJKk16R5cJKO8Z96bkgUl2olV7\",\n","  \"model\": \"text-davinci-003\",\n","  \"object\": \"text_completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 265,\n","    \"prompt_tokens\": 3420,\n","    \"total_tokens\": 3685\n","  }\n","}\n"]}],"source":["print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96803,"status":"ok","timestamp":1670480830877,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"qnbb7tVXRPmt","outputId":"1773324c-7102-40e4-db2c-283c4511710c"},"outputs":[{"name":"stdout","output_type":"stream","text":["finished test 2\n","finished test 3\n","finished test 4\n","finished test 5\n","finished test 6\n","finished test 7\n"]}],"source":["# Test using prompts from test set (unseen)\n","raw_data = []\n","with open('../data/train/lda-train-6.csv', 'r') as orig_data:\n","  reader = csv.reader(orig_data, delimiter = ',')\n","  i = 0\n","  for row in reader:\n","    if i > 1 and i < 1000:\n","      raw_data.append(row)\n","    i += 1\n","\n","num_samples = 1   # Number of samples for each topic\n","by_topic = [[] for i in range(6)]\n","for artist, topic_id, lyric in raw_data:\n","  id = int(topic_id)\n","  if len(by_topic[id]) < num_samples * 6:   # Limited to 6 samples for token reason\n","    by_topic[id].append((artist, lyric))\n","\n","# input_artist = \"Taylor Swift\"\n","# input_topic = 0\n","\n","with open('../data/test/lda-test-6-formatted.csv', 'r') as test:\n","  reader = csv.reader(test, delimiter = ',')\n","  with open('../data/out/out-fewshot-topic-test.txt', 'w') as out_topic:\n","    with open('../data/out/out-fewshot-gen-test.txt', 'w') as out_gen:\n","      i = 0\n","      for row in reader:\n","        if i > 1 and i < 8:   # Only using 6 examples; ran into API access denied issues\n","          prompt = row[0]\n","          input_artist = prompt.split(';')[0]\n","          input_topic = int(prompt.split(';')[1][0])\n","          prompts_topic = [\"\" for i in range(6)]  # Examples separated by topic\n","          prompt_gen = \"\"  # Example with all topics\n","          for id, topic in enumerate(by_topic):\n","            j = 0\n","            for artist, lyric in topic:\n","              prompts_topic[id] += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","              if j < num_samples:\n","                prompt_gen += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","                j += 1\n","            prompts_topic[id] += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\n Lyrics: \"\n","          prompt_gen += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\nLyrics: \"\n","\n","          # Example includes all topics\n","          result = openai.Completion.create(\n","              model=\"text-davinci-003\",\n","              prompt=prompt_gen,\n","              max_tokens=400,\n","              stop=\"###\")\n","          out_gen.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","\n","          # Examples includes requested topic\n","          result = openai.Completion.create(\n","              model=\"text-davinci-003\",\n","              prompt=prompts_topic[input_topic],\n","              max_tokens=400,\n","              stop=\"###\")\n","          out_topic.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","\n","          print(\"finished test \" + str(i))\n","          \n","        i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116229,"status":"ok","timestamp":1670481731108,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"0kTGJHD3cERY","outputId":"c60fb25d-5f76-4e38-9f49-f3bce29cd828"},"outputs":[{"name":"stdout","output_type":"stream","text":["finished test 2\n","finished test 3\n","finished test 4\n","finished test 5\n","finished test 6\n","finished test 7\n"]}],"source":["# Test using prompts from train set (seen)\n","raw_data = []\n","with open('../data/train/lda-train-6.csv', 'r') as orig_data:\n","  reader = csv.reader(orig_data, delimiter = ',')\n","  i = 0\n","  for row in reader:\n","    if i > 1 and i < 1000:\n","      raw_data.append(row)\n","    i += 1\n","\n","num_samples = 1   # Number of samples for each topic\n","by_topic = [[] for i in range(6)]\n","for artist, topic_id, lyric in raw_data:\n","  id = int(topic_id)\n","  if len(by_topic[id]) < num_samples * 6:   # Limited to 6 samples for token reason\n","    by_topic[id].append((artist, lyric))\n","\n","# input_artist = \"Taylor Swift\"\n","# input_topic = 0\n","\n","with open('../data/train/lda-train-6-formatted.csv', 'r') as test:\n","  reader = csv.reader(test, delimiter = ',')\n","  with open('../data/out/out-fewshot-topic-val.txt', 'w') as out_topic:\n","    with open('../data/out/out-fewshot-gen-val.txt', 'w') as out_gen:\n","      i = 0\n","      for row in reader:\n","        if i > 1 and i < 8:   # Only using 6 examples; ran into API access denied issues\n","          prompt = row[0]\n","          input_artist = prompt.split(';')[0]\n","          input_topic = int(prompt.split(';')[1][0])\n","          prompts_topic = [\"\" for i in range(6)]  # Examples separated by topic\n","          prompt_gen = \"\"  # Example with all topics\n","          for id, topic in enumerate(by_topic):\n","            j = 0\n","            for artist, lyric in topic:\n","              prompts_topic[id] += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","              if j < num_samples:\n","                prompt_gen += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","                j += 1\n","            prompts_topic[id] += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\n Lyrics: \"\n","          prompt_gen += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\nLyrics: \"\n","\n","          # Example includes all topics\n","          result = openai.Completion.create(\n","              model=\"text-davinci-003\",\n","              prompt=prompt_gen,\n","              max_tokens=400,\n","              stop=\"###\")\n","          out_gen.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","\n","          # Examples includes requested topic\n","          result = openai.Completion.create(\n","              model=\"text-davinci-003\",\n","              prompt=prompts_topic[input_topic],\n","              max_tokens=400,\n","              stop=\"###\")\n","          out_topic.write(prompt + \"<START>\" + result.choices[0][\"text\"] + \"<END>\\n\\n\")\n","\n","          print(\"finished test \" + str(i))\n","          \n","        i += 1"]},{"cell_type":"markdown","metadata":{"id":"HApSv5Dn4k2Z"},"source":["### Using 40 topic set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkGO2I2x4oUg"},"outputs":[],"source":["import random\n","\n","# Samples w same topics\n","raw_data = []\n","with open('../data/train/big-lda-train-40.csv', 'r') as orig_data:\n","  reader = csv.reader(orig_data, delimiter = ',')\n","  i = 0\n","  for row in reader:\n","    if i > 0 and i < 2000:\n","      raw_data.append(row)\n","    i += 1\n","\n","num_samples = 1   # Number of samples for each topic\n","num_total = 13  # Total number of examples per prompt\n","by_topic = [[] for i in range(40)]\n","for artist, topic_id, lyric in raw_data:\n","  id = int(topic_id)\n","  if len(by_topic[id]) < num_samples * num_total:\n","    by_topic[id].append((artist, lyric))\n","\n","input_artist = \"Taylor Swift\"\n","input_topic = 0\n","sample_topics = random.sample(range(40), num_total)  # topics to include in generalized examples\n","\n","prompts_topic = [\"\" for i in range(40)]  # Examples separated by topic\n","prompt_gen = \"\"  # Example with all topics\n","for id, topic in enumerate(by_topic):\n","  for i, (artist, lyric) in enumerate(topic):\n","    prompts_topic[id] += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","    if id in sample_topics and i == 0:\n","      prompt_gen += \"Artist: \" + artist + \"\\nTopic ID: \" + str(id) + \"\\nLyrics: \" + lyric + \"\\n###\\n\"\n","  prompts_topic[id] += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\n Lyrics: \"\n","prompt_gen += \"Artist: \" + input_artist + \"\\nTopic ID: \" + str(input_topic) + \"\\nLyrics: \""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670372719807,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"j_CFInzA-GjE","outputId":"1a9d8919-1749-446b-fe82-8d6b66e2f7fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["jessie j\n","\n","grace jones\n","\n","vektor\n","\n","editors\n","\n","looney tunes songs\n","\n","george jones\n","\n","superchunk\n","\n","carole king\n","\n","the decemberists\n","\n","mercyme\n","\n","lynyrd skynyrd\n","\n","bright eyes\n","\n","pat benatar\n","\n"]}],"source":["for artist, _ in by_topic[input_topic]:\n","  print(artist + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7772,"status":"ok","timestamp":1670372199679,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"abY9URCI6Rli","outputId":"2a06bcff-6abd-40eb-a31c-d5c0f36e79d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","I'd like to be everything you want, hey,\n","So won't you tell me everything that's on your mind?\n","'Cause I, I believe in second chances,\n","If you're ready, it could feel so right.\n","\n","If I could take the trend and turn it into truth\n","I'm here to give you love and all I've got to give\n","I'm ready for whatever life has for me\n","And don't let go of what we had at the beginning \n","\n","I wanna be the reason you let down your guard\n","I want to be the one to heal your broken heart\n","So let me in, I promise I won't hurt you again\n","If you let me, I could be\n","The one to fight for the love we could make\n","\n","I could be strong for the both of us (Oh, for the both of us)\n","And try not to be scared, when things don't go our way\n","I wanna be the one, the one that you love\n","The one that you care for, the one that you trust.\n"]}],"source":["# Example includes all topics\n","result = openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt=prompt_gen,\n","    max_tokens=400,\n","    stop=\"###\")\n","print(result.choices[0][\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1670372199681,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"_EYlfuJx6Rlj","outputId":"212c5664-c710-49ca-e2ee-aa47ecacfc9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"text\": \"\\nI'd like to be everything you want, hey,\\nSo won't you tell me everything that's on your mind?\\n'Cause I, I believe in second chances,\\nIf you're ready, it could feel so right.\\n\\nIf I could take the trend and turn it into truth\\nI'm here to give you love and all I've got to give\\nI'm ready for whatever life has for me\\nAnd don't let go of what we had at the beginning \\n\\nI wanna be the reason you let down your guard\\nI want to be the one to heal your broken heart\\nSo let me in, I promise I won't hurt you again\\nIf you let me, I could be\\nThe one to fight for the love we could make\\n\\nI could be strong for the both of us (Oh, for the both of us)\\nAnd try not to be scared, when things don't go our way\\nI wanna be the one, the one that you love\\nThe one that you care for, the one that you trust.\"\n","    }\n","  ],\n","  \"created\": 1670372193,\n","  \"id\": \"cmpl-6KcOv6Q6gLAGRKNGDL5wzDAKxaROz\",\n","  \"model\": \"text-davinci-003\",\n","  \"object\": \"text_completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 220,\n","    \"prompt_tokens\": 3264,\n","    \"total_tokens\": 3484\n","  }\n","}\n"]}],"source":["print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5593,"status":"ok","timestamp":1670372612840,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"IlZMGaz76Rlk","outputId":"63d3d7da-5447-40e3-ec74-c4ca3ef20f38"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","So it's gonna be forever Or it's gonna go down in flames You can tell me when it's over If the high was worth the pain Got a long list of ex-lovers They'll tell you I'm insane 'Cause you know I love the players And you love the game  'Cause we're young and we're reckless We'll take this way too far And leave you breathless Or with a nasty scar Got a long list of ex-lovers They'll tell you I'm insane But I've got a blank space baby And I'll write your name  So it's gonna be forever Or it's gonna go down in flames You can tell me when it's over If the high was worth the pain 'Cause we're young and we're reckless We'll take this way too far And leave you breathless Or with a nasty scar Got a long list of ex-lovers They'll tell you I'm insane But I've got a blank space baby And I'll write your name\n"]}],"source":["# Examples includes requested topic\n","result = openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt=prompts_topic[input_topic],\n","    max_tokens=400,\n","    stop=\"###\")\n","print(result.choices[0][\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1670372639517,"user":{"displayName":"AVALON VINELLA","userId":"13083077728860304970"},"user_tz":480},"id":"8lk5cKw96Rll","outputId":"1ad511e2-c4ff-47e2-880a-6c5b098f6687"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"text\": \"\\nSo it's gonna be forever Or it's gonna go down in flames You can tell me when it's over If the high was worth the pain Got a long list of ex-lovers They'll tell you I'm insane 'Cause you know I love the players And you love the game  'Cause we're young and we're reckless We'll take this way too far And leave you breathless Or with a nasty scar Got a long list of ex-lovers They'll tell you I'm insane But I've got a blank space baby And I'll write your name  So it's gonna be forever Or it's gonna go down in flames You can tell me when it's over If the high was worth the pain 'Cause we're young and we're reckless We'll take this way too far And leave you breathless Or with a nasty scar Got a long list of ex-lovers They'll tell you I'm insane But I've got a blank space baby And I'll write your name\"\n","    }\n","  ],\n","  \"created\": 1670372609,\n","  \"id\": \"cmpl-6KcVdiWGyyje1m55FH4nUSHTWMYQe\",\n","  \"model\": \"text-davinci-003\",\n","  \"object\": \"text_completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 202,\n","    \"prompt_tokens\": 3645,\n","    \"total_tokens\": 3847\n","  }\n","}\n"]}],"source":["print(result)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}